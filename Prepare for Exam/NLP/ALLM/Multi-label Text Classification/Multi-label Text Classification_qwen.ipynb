{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 1. การติดตั้งและ Import Library\n",
    "\n",
    "# ติดตั้ง library ที่จำเป็น\n",
    "!pip install -q transformers torch datasets accelerate\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ตรวจสอบและตั้งค่าอุปกรณ์ (GPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"อุปกรณ์ที่ใช้: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 2. การเตรียมข้อมูล\n",
    "\n",
    "print(\"กำลังโหลด Wongnai Reviews Dataset...\")\n",
    "try:\n",
    "    dataset = load_dataset(\"wongnai/wongnai_reviews\", split='train')\n",
    "    df = dataset.to_pandas()\n",
    "    print(f\"โหลดข้อมูลดิบสำเร็จ จำนวน {len(df)} รีวิว\")\n",
    "\n",
    "    # สร้างข้อมูล test โดยสุ่มมา 500 ตัวอย่าง\n",
    "    test_df = df.sample(n=500, random_state=42).reset_index(drop=True)\n",
    "    test_df = test_df[['review_body']].rename(columns={'review_body': 'review_text'})\n",
    "    test_df['review_id'] = test_df.index\n",
    "\n",
    "    print(\"\\nสร้าง Test Set สำหรับทดลอง Pipeline สำเร็จ\")\n",
    "    print(\"ตัวอย่างข้อมูล:\")\n",
    "    print(test_df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ไม่สามารถโหลด Dataset ได้: {e}\")\n",
    "    # สร้างข้อมูลสำรองหากโหลดไม่ได้\n",
    "    dummy_data = {\n",
    "        'review_id': [1, 2, 3],\n",
    "        'review_text': [\n",
    "            \"อาหารอร่อยมากครับ โดยเฉพาะกุ้งเผา แต่รอนานไปหน่อย ราคาไม่แพง\",\n",
    "            \"รสชาติเฉยๆนะ แต่ร้านสวยมาก บรรยากาศดี\",\n",
    "            \"ร้านหาง่าย เดินทางสะดวก\"\n",
    "        ]\n",
    "    }\n",
    "    test_df = pd.DataFrame(dummy_data)\n",
    "    print(\"\\nสร้าง Test Set ตัวอย่างขึ้นมาแทน:\")\n",
    "    print(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 3. การโหลดโมเดล Qwen2 และ Tokenizer\n",
    "\n",
    "model_id = \"Qwen/Qwen2-7B-Instruct\"\n",
    "\n",
    "print(f\"กำลังโหลด Tokenizer จาก '{model_id}'...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "print(f\"กำลังโหลดโมเดล '{model_id}'...\")\n",
    "print(\"หมายเหตุ: ขั้นตอนนี้ต้องการ VRAM ประมาณ 14-16 GB\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"\\nโหลดโมเดลและ Tokenizer สำเร็จ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 4. การออกแบบ Prompt สำหรับ Qwen2\n",
    "\n",
    "# สร้างโครงสร้าง Prompt แบบ Chat ที่มีประสิทธิภาพสำหรับ Qwen2\n",
    "# 1. System Prompt: สั่งบทบาทและรูปแบบผลลัพธ์ที่ชัดเจนที่สุด\n",
    "# 2. Few-Shot Examples: ใส่ตัวอย่างที่ดี 3 กรณี (ผสม, เฉพาะทาง, และไม่พบ)\n",
    "# 3. Final User Prompt: คำถามสุดท้ายที่เราจะใส่รีวิวเข้าไป\n",
    "\n",
    "chat_template = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"คุณคือผู้เชี่ยวชาญในการวิเคราะห์รีวิว หน้าที่ของคุณคือสกัด 'aspect' และ 'sentiment' จากรีวิวที่กำหนด และต้องตอบกลับเป็น JSON Array เท่านั้น ห้ามมีข้อความอธิบายอื่นใดๆ ถ้าไม่พบ aspect ที่เกี่ยวข้อง ให้ตอบกลับเป็น Array ว่าง `[]`\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"รีวิว: \"อาหารอร่อยมาก แต่ราคาแอบแรงไปนิดนึง บรรยากาศร้านดีครับ\" จงสกัดแง่มุมและความรู้สึก\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"[{\"aspect\": \"รสชาติ\", \"sentiment\": \"positive\"}, {\"aspect\": \"ราคา\", \"sentiment\": \"negative\"}, {\"aspect\": \"บรรยากาศ\", \"sentiment\": \"positive\"}]\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"รีวิว: \"รสชาติโอเค พอใช้ได้ แต่พนักงานบริการช้ามาก\" จงสกัดแง่มุมและความรู้สึก\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"[{\"aspect\": \"รสชาติ\", \"sentiment\": \"neutral\"}, {\"aspect\": \"บริการ\", \"sentiment\": \"negative\"}]\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"รีวิว: \"ร้านหาง่ายดี เดินทางสะดวก\" จงสกัดแง่มุมและความรู้สึก\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"[]\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"รีวิว: \"{review_text}\" จงสกัดแง่มุมและความรู้สึก\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ใช้ .apply_chat_template เพื่อสร้าง prompt ที่สมบูรณ์ตามรูปแบบของ Qwen2\n",
    "# นี่คือวิธีที่ถูกต้องและให้ผลดีที่สุด\n",
    "prompt_example = tokenizer.apply_chat_template(\n",
    "    chat_template[:-1], # แสดงตัวอย่าง prompt ที่ไม่มี review จริง\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(\"--- ตัวอย่าง Prompt ที่จะส่งให้โมเดล (ก่อนเติมรีวิวจริง) ---\")\n",
    "print(prompt_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e965d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 5. การเริ่ม Pipeline การทำนายผล\n",
    "\n",
    "results = []\n",
    "# ในการทดลอง สามารถลดจำนวน test_subset ลงได้\n",
    "test_subset = test_df\n",
    "\n",
    "print(f\"กำลังเริ่มทำนายผลสำหรับรีวิว {len(test_subset)} ตัวอย่าง...\")\n",
    "\n",
    "for index, row in tqdm(test_subset.iterrows(), total=len(test_subset)):\n",
    "    review_id = row['review_id']\n",
    "    review_text = row['review_text']\n",
    "\n",
    "    # สร้าง Prompt สำหรับรีวิวปัจจุบัน\n",
    "    current_chat = [\n",
    "        *chat_template[:-1], # นำ template ทั้งหมดมาใช้\n",
    "        {\"role\": \"user\", \"content\": chat_template[-1][\"content\"].format(review_text=review_text)}\n",
    "    ]\n",
    "\n",
    "    # แปลง prompt เป็น token id ตามรูปแบบของโมเดล\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        current_chat,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # สั่งให้โมเดลสร้างข้อความ\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=False, # ไม่ต้องสุ่มคำตอบเพื่อให้ได้ผลลัพธ์ที่แน่นอน\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # ถอดรหัสเฉพาะส่วนที่โมเดลสร้างขึ้นใหม่\n",
    "    response_text = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    # --- ส่วนของการ Parse ผลลัพธ์ที่รัดกุม ---\n",
    "    try:\n",
    "        # ค้นหาตำแหน่งเริ่มต้น `[` และตำแหน่งสุดท้าย `]` ของ JSON\n",
    "        start_index = response_text.find('[')\n",
    "        end_index = response_text.rfind(']')\n",
    "        \n",
    "        # ถ้าหาเจอทั้งคู่ ให้ตัดมาเฉพาะส่วนของ JSON\n",
    "        if start_index != -1 and end_index != -1:\n",
    "            json_part = response_text[start_index : end_index + 1]\n",
    "            parsed_output = json.loads(json_part)\n",
    "\n",
    "            if isinstance(parsed_output, list):\n",
    "                for item in parsed_output:\n",
    "                    if isinstance(item, dict) and 'aspect' in item and 'sentiment' in item:\n",
    "                        results.append({\n",
    "                            'id': review_id,\n",
    "                            'aspect': item['aspect'],\n",
    "                            'sentiment': item['sentiment']\n",
    "                        })\n",
    "        # ถ้าหา JSON ไม่เจอ ก็จะข้ามไป (ซึ่งไม่ควรเกิดจาก prompt ที่ดี)\n",
    "\n",
    "    except (json.JSONDecodeError, IndexError) as e:\n",
    "        print(f\"\\n[Error] ไม่สามารถ Parse JSON สำหรับ review_id {review_id}.\")\n",
    "        print(f\"  -> ผลลัพธ์จากโมเดล: '{response_text}'\")\n",
    "\n",
    "print(\"\\nการทำนายผลเสร็จสิ้น\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 6. การสร้างไฟล์ Submission\n",
    "\n",
    "print(\"กำลังสร้างไฟล์ submission.csv...\")\n",
    "\n",
    "if not results:\n",
    "    print(\"ไม่พบผลลัพธ์ที่ถูกต้อง! ไม่สามารถสร้างไฟล์ submission ได้\")\n",
    "else:\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    submission_df = submission_df[['id', 'aspect', 'sentiment']]\n",
    "\n",
    "    print(\"\\nตัวอย่างผลลัพธ์ 10 แถวแรก:\")\n",
    "    print(submission_df.head(10))\n",
    "\n",
    "    submission_df.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"\\nสร้างไฟล์ submission.csv สำเร็จ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf793256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a925b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd978777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8d381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f96743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ec6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad2842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcea4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
