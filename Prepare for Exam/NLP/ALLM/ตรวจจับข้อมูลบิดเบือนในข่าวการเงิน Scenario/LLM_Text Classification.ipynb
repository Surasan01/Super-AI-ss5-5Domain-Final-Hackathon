{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b4ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 1. การติดตั้งและ Import Library\n",
    "\n",
    "# ติดตั้ง Library ที่จำเป็น\n",
    "!pip install -q transformers[torch] torch datasets accelerate scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ตรวจสอบและตั้งค่าอุปกรณ์ (GPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"อุปกรณ์ที่ใช้: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 2. การเตรียมข้อมูลและตัวอย่าง Few-Shot\n",
    "\n",
    "print(\"กำลังโหลด Thai Fake News Detection Dataset...\")\n",
    "# โหลดชุดข้อมูลจาก Hugging Face Hub\n",
    "raw_dataset = load_dataset(\"EXt1/Thai-True-Fake-News\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee524f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# แปลง Dataset เป็น DataFrame ก่อน\n",
    "df = raw_dataset['train'].to_pandas()\n",
    "\n",
    "# เปลี่ยนชื่อคอลัมน์ใน DataFrame\n",
    "df = df.rename(columns={'Title': 'text', 'Verification_Status': 'label'})\n",
    "\n",
    "# อัปเดต raw_dataset โดยแปลงจาก DataFrame กลับเป็น Dataset\n",
    "\n",
    "# สร้าง Dataset ใหม่จาก DataFrame ที่เปลี่ยนชื่อคอลัมน์แล้ว\n",
    "updated_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# สร้าง DatasetDict ใหม่\n",
    "raw_dataset = DatasetDict({\n",
    "    'train': updated_dataset\n",
    "})\n",
    "\n",
    "print(\"เปลี่ยนชื่อคอลัมน์สำเร็จ:\")\n",
    "print(f\"DataFrame columns: {df.columns.tolist()}\")\n",
    "print(f\"Dataset features: {raw_dataset['train'].features}\")\n",
    "print(\"\\nตัวอย่างข้อมูลหลังเปลี่ยนชื่อ:\")\n",
    "print(df[['text', 'label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a828e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = raw_dataset['train'].to_pandas()\n",
    "df = df.dropna(subset=['text', 'label']).drop_duplicates(subset=['text'])\n",
    "\n",
    "# จำลองคอลัมน์จากโจทย์\n",
    "df['news_title'] = df['text'].str[:30]\n",
    "df['news_content'] = df['text'].str[30:]\n",
    "\n",
    "# --- คัดเลือกตัวอย่างคุณภาพสูงสำหรับ Few-Shot Prompt ---\n",
    "# ตัวอย่างที่ 1: ข่าวจริง (Real News)\n",
    "real_news_example = df[df['label'] == 'real'].iloc[10] # เลือกตัวอย่างที่ชัดเจน\n",
    "# ตัวอย่างที่ 2: ข่าวปลอม (Fake News)\n",
    "fake_news_example = df[df['label'] == 'fake'].iloc[5] # เลือกตัวอย่างที่ชัดเจน\n",
    "\n",
    "# --- สร้างข้อมูลสำหรับ Test Set เพื่อจำลองการแข่งขัน ---\n",
    "test_df = df.sample(n=100, random_state=42) # ลดขนาดเพื่อความรวดเร็วในการทดลอง\n",
    "test_df['news_id'] = range(len(test_df))\n",
    "test_df_labels = test_df['label'].apply(lambda x: 1 if x == 'fake' else 0).values\n",
    "\n",
    "print(\"คัดเลือกตัวอย่าง Few-shot และเตรียม Test set สำเร็จ\")\n",
    "print(\"\\n--- ตัวอย่างข่าวจริง ---\")\n",
    "print(f\"Title: {real_news_example['news_title']}\")\n",
    "print(\"\\n--- ตัวอย่างข่าวปลอม ---\")\n",
    "print(f\"Title: {fake_news_example['news_title']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e36dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 3. การโหลดโมเดล LLM และ Tokenizer\n",
    "\n",
    "model_id = \"Qwen/Qwen2-7B-Instruct\"\n",
    "print(f\"กำลังโหลด Tokenizer และโมเดล LLM: '{model_id}'...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model_llm = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16, # ใช้ bfloat16 เพื่อลดการใช้ VRAM และเพิ่มความเร็ว\n",
    "    device_map=\"auto\"           # โหลดโมเดลข้าม GPU อัตโนมัติหากมีหลายตัว\n",
    ")\n",
    "model_llm.eval() # ตั้งเป็น evaluation mode\n",
    "\n",
    "print(\"โหลดโมเดล LLM สำเร็จ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 4. การออกแบบ Prompt (Few-Shot & Chain-of-Thought)\n",
    "\n",
    "def create_few_shot_prompt(news_title, news_content):\n",
    "    \"\"\"\n",
    "    สร้าง Prompt ที่สมบูรณ์แบบ Few-shot และ Chain-of-Thought\n",
    "    \"\"\"\n",
    "    # นี่คือ Chat Template ที่เราจะส่งให้โมเดล\n",
    "    chat = [\n",
    "        # 1. System Message: กำหนดบทบาทและคำสั่งหลัก\n",
    "        {\"role\": \"system\", \"content\": \"คุณคือนักสืบสวนข่าวปลอมผู้เชี่ยวชาญด้านการเงิน คุณต้องวิเคราะห์ข่าวตามขั้นตอนที่กำหนด และตอบกลับเป็น JSON object ที่มี key 'analysis' และ 'prediction' เท่านั้น โดยค่าของ prediction ต้องเป็น 'เชื่อถือได้' หรือ 'ข้อมูลบิดเบือน' อย่างใดอย่างหนึ่ง\"},\n",
    "\n",
    "        # 2. Few-shot Example 1 (ข่าวจริง)\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"จงวิเคราะห์ข่าวต่อไปนี้:\n",
    "หัวข้อ: \"{real_news_example['news_title']}\"\n",
    "เนื้อหา: \"{real_news_example['news_content']}\"\n",
    "\n",
    "ขั้นตอนการวิเคราะห์:\n",
    "1. มีการอ้างแหล่งข้อมูลที่ไม่น่าเชื่อถือหรือไม่?\n",
    "2. มีการใช้ภาษาที่ชี้นำอารมณ์มากกว่าข้อเท็จจริงหรือไม่?\n",
    "3. มีการกล่าวอ้างเกินจริง (เช่น \"การันตีผลตอบแทน\") หรือไม่?\n",
    "4. สรุป: ข่าวนี้มีแนวโน้มเป็นข้อมูลบิดเบือนหรือไม่? ให้ตอบว่า \"ข่าวจริง\" หรือ \"ข่าวปลอม\"\n",
    "\"\"\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"\"{\n",
    "    \"analysis\": \"1. ข่าวมีการอ้างอิงถึงหน่วยงานภาครัฐและข้อมูลที่ตรวจสอบได้ 2. ภาษาที่ใช้เป็นทางการและเน้นข้อเท็จจริง ไม่มีการชี้นำอารมณ์ 3. ไม่มีการกล่าวอ้างเกินจริงหรือรับประกันผลตอบแทน 4. สรุปแล้ว ข่าวนี้มีความน่าเชื่อถือสูง\",\n",
    "    \"prediction\": \"ข่าวจริง\"\n",
    "}\"\"\"},\n",
    "\n",
    "        # 3. Few-shot Example 2 (ข่าวปลอม)\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"จงวิเคราะห์ข่าวต่อไปนี้:\n",
    "หัวข้อ: \"{fake_news_example['news_title']}\"\n",
    "เนื้อหา: \"{fake_news_example['news_content']}\"\n",
    "\n",
    "ขั้นตอนการวิเคราะห์:\n",
    "1. มีการอ้างแหล่งข้อมูลที่ไม่น่าเชื่อถือหรือไม่?\n",
    "2. มีการใช้ภาษาที่ชี้นำอารมณ์มากกว่าข้อเท็จจริงหรือไม่?\n",
    "3. มีการกล่าวอ้างเกินจริง (เช่น \"การันตีผลตอบแทน\") หรือไม่?\n",
    "4. สรุป: ข่าวนี้มีแนวโน้มเป็นข้อมูลบิดเบือนหรือไม่? ให้ตอบว่า \"ข่าวจริง\" หรือ \"ข่าวปลอม\"\n",
    "\"\"\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"\"{\n",
    "    \"analysis\": \"1. ข่าวไม่มีการอ้างอิงแหล่งข้อมูลที่ชัดเจน และมาจากบุคคลที่ไม่เป็นที่รู้จัก 2. ภาษาที่ใช้เร่งเร้าและกระตุ้นความโลภ ('ด่วน', 'รวยเร็ว') มากกว่าให้ข้อมูล 3. มีการกล่าวอ้างถึงผลตอบแทนที่สูงเกินจริงและง่ายดาย 4. สรุปแล้ว ข่าวนี้มีลักษณะของข้อมูลบิดเบือนเพื่อหลอกลวง\",\n",
    "    \"prediction\": \"ข่าวปลอม\"\n",
    "}\"\"\"},\n",
    "\n",
    "        # 4. User Query (ข่าวที่เราต้องการวิเคราะห์)\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"จงวิเคราะห์ข่าวต่อไปนี้:\n",
    "หัวข้อ: \"{news_title}\"\n",
    "เนื้อหา: \"{news_content}\"\n",
    "\n",
    "ขั้นตอนการวิเคราะห์:\n",
    "1. มีการอ้างแหล่งข้อมูลที่ไม่น่าเชื่อถือหรือไม่?\n",
    "2. มีการใช้ภาษาที่ชี้นำอารมณ์มากกว่าข้อเท็จจริงหรือไม่?\n",
    "3. มีการกล่าวอ้างเกินจริง (เช่น \"การันตีผลตอบแทน\") หรือไม่?\n",
    "4. สรุป: ข่าวนี้มีแนวโน้มเป็นข้อมูลบิดเบือนหรือไม่? ให้ตอบว่า \"ข่าวจริง\" หรือ \"ข่าวปลอม\"\n",
    "\"\"\"},\n",
    "    ]\n",
    "    return chat\n",
    "\n",
    "# ทดสอบสร้าง Prompt\n",
    "test_prompt = create_few_shot_prompt(\"ทดสอบหัวข้อ\", \"ทดสอบเนื้อหา\")\n",
    "print(\"สร้าง Template Prompt สำเร็จ\")\n",
    "# print(json.dumps(test_prompt, indent=2, ensure_ascii=False)) # สามารถ uncomment เพื่อดูโครงสร้างเต็มๆ ได้\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c31aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 5. การทำนายผลด้วย LLM และการ Parsing\n",
    "\n",
    "results = []\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Predicting with LLM\"):\n",
    "    # สร้าง Prompt สำหรับข่าวแต่ละชิ้น\n",
    "    prompt = create_few_shot_prompt(row['news_title'], row['news_content'])\n",
    "    \n",
    "    # แปลง Prompt เป็น Token IDs และส่งเข้า GPU\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        prompt, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\"\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # จำกัดความยาว Input เพื่อป้องกัน Error\n",
    "    if inputs.shape[1] > 4096:\n",
    "        inputs = inputs[:, -4096:]\n",
    "\n",
    "    # สั่งให้โมเดลสร้างข้อความ\n",
    "    with torch.no_grad():\n",
    "        outputs = model_llm.generate(\n",
    "            inputs,\n",
    "            max_new_tokens=256,         # จำกัดความยาวของคำตอบ\n",
    "            do_sample=False,            # ไม่ต้องสุ่มคำตอบเพื่อให้ผลลัพธ์คงที่\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # ถอดรหัสคำตอบ\n",
    "    response_text = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    # พยายาม Parse JSON จากคำตอบ\n",
    "    try:\n",
    "        start_index = response_text.find('{')\n",
    "        end_index = response_text.rfind('}')\n",
    "        json_part = response_text[start_index : end_index + 1]\n",
    "        data = json.loads(json_part)\n",
    "        prediction = data.get('prediction', 'error')\n",
    "    except (json.JSONDecodeError, AttributeError, ValueError):\n",
    "        prediction = 'error' # หากเกิดข้อผิดพลาดในการ parse\n",
    "\n",
    "    results.append(prediction)\n",
    "\n",
    "# เพิ่มผลลัพธ์ลงใน DataFrame\n",
    "test_df['llm_prediction'] = results\n",
    "\n",
    "print(\"\\nทำนายผลด้วย LLM สำเร็จ\")\n",
    "print(\"ตัวอย่างผลการทำนาย:\")\n",
    "print(test_df[['news_title', 'label', 'llm_prediction']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 6. การประเมินผลและสร้างไฟล์ Submission\n",
    "\n",
    "# แปลง prediction ที่เป็น string เป็น label ตัวเลข (0 หรือ 1)\n",
    "def to_label(pred_text):\n",
    "    if \"ข้อมูลบิดเบือน\" in pred_text:\n",
    "        return 1\n",
    "    elif \"เชื่อถือได้\" in pred_text:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1 # คืนค่า -1 หากเป็น Error หรือคำตอบไม่ตรงรูปแบบ\n",
    "\n",
    "test_df['predicted_label'] = test_df['llm_prediction'].apply(to_label)\n",
    "\n",
    "# กรองแถวที่เกิด Error ออกก่อนประเมินผล\n",
    "eval_df = test_df[test_df['predicted_label'] != -1]\n",
    "actual_labels = eval_df['label'].apply(lambda x: 1 if x == 'fake' else 0)\n",
    "predicted_labels = eval_df['predicted_label']\n",
    "\n",
    "\n",
    "# ประเมินผลเทียบกับคำตอบจริง (เพื่อดูประสิทธิภาพของ Prompt)\n",
    "if not eval_df.empty:\n",
    "    accuracy = accuracy_score(actual_labels, predicted_labels)\n",
    "    f1 = f1_score(actual_labels, predicted_labels)\n",
    "    print(\"\\n--- ประสิทธิภาพของโมเดลบน Test Set ---\")\n",
    "    print(f\"accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"จำนวนที่ทำนายได้สำเร็จ: {len(eval_df)}/{len(test_df)}\")\n",
    "else:\n",
    "    print(\"\\nไม่สามารถประเมินผลได้เนื่องจาก LLM ไม่ได้ให้คำตอบที่ถูกต้อง\")\n",
    "\n",
    "# --- สร้างไฟล์ Submission ---\n",
    "# สำหรับแถวที่เกิด Error อาจจะต้องใช้วิธีสำรอง หรือเติมค่าที่พบบ่อยที่สุด (Majority class)\n",
    "# ในที่นี้ เราจะเติม 0 สำหรับแถวที่เกิด error\n",
    "final_predictions = test_df['predicted_label'].copy()\n",
    "final_predictions[final_predictions == -1] = 0 # เติม 0 (เชื่อถือได้) สำหรับแถวที่ error\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'news_id': test_df['news_id'],\n",
    "    'label': final_predictions.astype(int)\n",
    "})\n",
    "\n",
    "print(\"\\nตัวอย่างข้อมูลในไฟล์ Submission:\")\n",
    "print(submission_df.head())\n",
    "\n",
    "# บันทึกเป็นไฟล์ CSV\n",
    "submission_df.to_csv(\"submission_llm.csv\", index=False)\n",
    "\n",
    "print(\"\\nสร้างไฟล์ submission_llm.csv สำเร็จ!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
