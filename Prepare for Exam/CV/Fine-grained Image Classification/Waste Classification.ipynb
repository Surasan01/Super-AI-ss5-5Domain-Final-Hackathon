{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e2fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Environment Installation\n",
    "\n",
    "# --- ติดตั้ง Libraries ---\n",
    "# timm: คลังโมเดล PyTorch ขนาดใหญ่ (Vision Transformers, ConvNeXt, etc.)\n",
    "# opendatasets: สำหรับดาวน์โหลดข้อมูลจาก Kaggle\n",
    "# albumentations: สำหรับทำ Data Augmentation\n",
    "!pip install timm opendatasets albumentations --quiet\n",
    "\n",
    "# --- Import Libraries ที่จำเป็น ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm.notebook import tqdm\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Setup Complete. Libraries including 'timm' are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbfac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration\n",
    "class CFG:\n",
    "    # --- Paths ---\n",
    "    DATA_DIR = './garbage-classification/'\n",
    "    \n",
    "    # --- Model ---\n",
    "    MODEL_NAME = 'convnext_tiny' # โมเดลจาก timm (ลองเปลี่ยนเป็น 'vit_base_patch16_224')\n",
    "    PRETRAINED = True\n",
    "    \n",
    "    # --- Training Parameters ---\n",
    "    IMG_SIZE = 224\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 10 # โจทย์จริงอาจใช้ 20-30\n",
    "    LEARNING_RATE = 1e-4\n",
    "    \n",
    "    # --- Environment ---\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    NUM_WORKERS = 2\n",
    "\n",
    "print(f\"Configuration loaded. Using device: {CFG.DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4036b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Acquisition & Preparation\n",
    "import opendatasets as od\n",
    "\n",
    "dataset_url = 'https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification'\n",
    "od.download(dataset_url)\n",
    "\n",
    "# --- สร้าง DataFrame จากโครงสร้างโฟลเดอร์ ---\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# วนลูปในแต่ละโฟลเดอร์ (ซึ่งเป็นชื่อคลาส)\n",
    "for class_name in os.listdir(CFG.DATA_DIR):\n",
    "    class_dir = os.path.join(CFG.DATA_DIR, class_name)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            image_paths.append(os.path.join(class_dir, img_name))\n",
    "            labels.append(class_name)\n",
    "\n",
    "df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
    "\n",
    "# --- แปลง Label (ชื่อคลาส) เป็นตัวเลข (Integer) ---\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# เก็บชื่อคลาสและจำนวนคลาสไว้ใน CFG\n",
    "CFG.CLASS_NAMES = label_encoder.classes_\n",
    "CFG.NUM_CLASSES = len(CFG.CLASS_NAMES)\n",
    "\n",
    "print(f\"Data prepared. Found {len(df)} images belonging to {CFG.NUM_CLASSES} classes.\")\n",
    "print(\"Class names:\", CFG.CLASS_NAMES)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb8067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Analyze and Handle Class Imbalance\n",
    "\n",
    "# --- แสดงกราฟการกระจายตัวของข้อมูล ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y=df['label'], order = df['label'].value_counts().index)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "# --- คำนวณ Weights สำหรับ Sampler ---\n",
    "class_counts = df['label'].value_counts().sort_index()\n",
    "class_weights = 1. / torch.tensor(class_counts.values, dtype=torch.float)\n",
    "sample_weights = class_weights[df['label_encoded'].values]\n",
    "\n",
    "print(\"Weights for each sample calculated for WeightedRandomSampler.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Augmentations and Custom Dataset\n",
    "\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(CFG.IMG_SIZE, CFG.IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=20, p=0.5),\n",
    "    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.3),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "valid_transforms = A.Compose([\n",
    "    A.Resize(CFG.IMG_SIZE, CFG.IMG_SIZE),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "class GarbageDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = row['image_path']\n",
    "        label = row['label_encoded']\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efdc4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Create DataLoaders with Sampler\n",
    "\n",
    "# แบ่งข้อมูล\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "# สร้าง Datasets\n",
    "train_dataset = GarbageDataset(train_df, transforms=train_transforms)\n",
    "val_dataset = GarbageDataset(val_df, transforms=valid_transforms)\n",
    "\n",
    "# สร้าง Sampler\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights[train_df.index], \n",
    "    num_samples=len(train_df), \n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# สร้าง DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CFG.BATCH_SIZE, \n",
    "    sampler=sampler, # <-- ใช้ Sampler ที่นี่\n",
    "    num_workers=CFG.NUM_WORKERS\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CFG.BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=CFG.NUM_WORKERS\n",
    ")\n",
    "\n",
    "print(f\"DataLoaders created. Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define Model, Loss, and Optimizer\n",
    "\n",
    "# สร้างโมเดลจาก timm\n",
    "model = timm.create_model(\n",
    "    CFG.MODEL_NAME,\n",
    "    pretrained=CFG.PRETRAINED,\n",
    "    num_classes=CFG.NUM_CLASSES\n",
    ").to(CFG.DEVICE)\n",
    "\n",
    "# กำหนด Loss Function และ Optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.LEARNING_RATE)\n",
    "\n",
    "print(f\"Model '{CFG.MODEL_NAME}' created with {CFG.NUM_CLASSES} output classes.\")\n",
    "# print(model) # Uncomment to see the model architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e47a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: The Training Loop\n",
    "\n",
    "best_val_acc = 0.0\n",
    "BEST_MODEL_PATH = f\"{CFG.MODEL_NAME}_best.pth\"\n",
    "\n",
    "for epoch in range(CFG.EPOCHS):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{CFG.EPOCHS} ---\")\n",
    "    \n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(CFG.DEVICE), labels.to(CFG.DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_loss, val_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "            images, labels = images.to(CFG.DEVICE), labels.to(CFG.DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += torch.sum(preds == labels.data)\n",
    "            \n",
    "    # คำนวณค่าเฉลี่ย\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    avg_train_acc = train_correct.double() / len(train_loader.sampler)\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    avg_val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} | Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}\")\n",
    "\n",
    "    # บันทึกโมเดลที่ดีที่สุด\n",
    "    if avg_val_acc > best_val_acc:\n",
    "        print(f\"Validation accuracy improved from {best_val_acc:.4f} to {avg_val_acc:.4f}. Saving model...\")\n",
    "        best_val_acc = avg_val_acc\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "\n",
    "print(\"\\nFinished Training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28dc7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Inference and Submission File Generation\n",
    "\n",
    "# --- สร้าง Test Loader (ในที่นี้เราใช้ validation set เป็นตัวจำลอง) ---\n",
    "test_df = val_df.copy().reset_index(drop=True)\n",
    "test_df['image_id'] = test_df['image_path'].apply(lambda x: os.path.basename(x))\n",
    "\n",
    "test_dataset = GarbageDataset(test_df, transforms=valid_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- โหลดโมเดลที่ดีที่สุดและทำนายผล ---\n",
    "model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in tqdm(test_loader, desc=\"Generating Predictions\"):\n",
    "        images = images.to(CFG.DEVICE)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "# แปลง index กลับเป็นชื่อคลาส\n",
    "predicted_labels = label_encoder.inverse_transform(all_preds)\n",
    "\n",
    "# --- สร้าง DataFrame สำหรับ Submission ---\n",
    "submission_df = pd.DataFrame({\n",
    "    'image_id': test_df['image_id'],\n",
    "    'label': predicted_labels\n",
    "})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nsubmission.csv created successfully!\")\n",
    "display(submission_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
