{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ef197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Configuration\n",
    "# --- ติดตั้ง Libraries ที่จำเป็น ---\n",
    "# opendatasets: สำหรับดาวน์โหลดข้อมูลจาก Kaggle\n",
    "# timm: คลังโมเดล SOTA (State-of-the-art) รวมถึง ConvNeXt\n",
    "# albumentations: สำหรับทำ Data Augmentation ที่มีประสิทธิภาพ\n",
    "!pip install opendatasets --quiet\n",
    "!pip install timm --quiet\n",
    "!pip install albumentations --quiet\n",
    "!pip install opencv-python-headless --quiet # OpenCV แบบไม่มีส่วน GUI\n",
    "\n",
    "# --- Import Libraries หลัก ---\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "\n",
    "# --- กำหนดค่า Configuration หลักของโปรเจกต์ ---\n",
    "class CFG:\n",
    "    # ตั้งค่าทั่วไป\n",
    "    PROJECT_NAME = \"Plant-Disease-Classification\"\n",
    "    MODEL_NAME = 'convnext_tiny' # โมเดลที่เราจะใช้จาก timm\n",
    "    \n",
    "    # กำหนด Path\n",
    "    DATA_PATH = \"./new-plant-diseases-dataset\"\n",
    "    \n",
    "    # ตั้งค่าการเทรน\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    IMG_SIZE = 224\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 5 # ลดจำนวน Epoch เพื่อให้รันจบเร็วในการทดลอง (ค่าที่แนะนำคือ 10-20)\n",
    "    LEARNING_RATE = 1e-4\n",
    "    NUM_WORKERS = 2 # จำนวน core ที่จะใช้โหลดข้อมูล\n",
    "    \n",
    "print(f\"จะทำการเทรนบนอุปกรณ์: {CFG.DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Acquisition\n",
    "import opendatasets as od\n",
    "\n",
    "# URL ของ Dataset บน Kaggle\n",
    "dataset_url = 'https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset'\n",
    "\n",
    "# ดาวน์โหลดข้อมูล (จะมีการถามหา username และ key จาก kaggle.json)\n",
    "od.download(dataset_url)\n",
    "\n",
    "# กำหนด Path ของข้อมูลที่ดาวน์โหลดมา\n",
    "# โครงสร้าง Path: ./new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\n",
    "# เราจะใช้ Path ที่ถูกต้อง\n",
    "CFG.TRAIN_PATH = os.path.join(CFG.DATA_PATH, 'New Plant Diseases Dataset(Augmented)', 'New Plant Diseases Dataset(Augmented)', 'train')\n",
    "CFG.VALID_PATH = os.path.join(CFG.DATA_PATH, 'New Plant Diseases Dataset(Augmented)', 'New Plant Diseases Dataset(Augmented)', 'valid')\n",
    "\n",
    "print(f\"Train Path: {CFG.TRAIN_PATH}\")\n",
    "print(f\"Valid Path: {CFG.VALID_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b350b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Exploration\n",
    "\n",
    "# ดึงชื่อคลาสทั้งหมดจากชื่อโฟลเดอร์ใน train path\n",
    "class_names = sorted(os.listdir(CFG.TRAIN_PATH))\n",
    "num_classes = len(class_names)\n",
    "print(f\"พบข้อมูลทั้งหมด {num_classes} คลาส\")\n",
    "\n",
    "# สร้าง DataFrame เพื่อนับจำนวนไฟล์ในแต่ละคลาสของ train และ valid set\n",
    "data_counts = []\n",
    "for class_name in class_names:\n",
    "    train_count = len(os.listdir(os.path.join(CFG.TRAIN_PATH, class_name)))\n",
    "    valid_count = len(os.listdir(os.path.join(CFG.VALID_PATH, class_name)))\n",
    "    data_counts.append({'Class': class_name, 'Train Count': train_count, 'Valid Count': valid_count})\n",
    "\n",
    "df_counts = pd.DataFrame(data_counts)\n",
    "print(\"สรุปจำนวนข้อมูลในแต่ละคลาส:\")\n",
    "display(df_counts)\n",
    "\n",
    "# เก็บชื่อคลาสและจำนวนคลาสไว้ใน CFG\n",
    "CFG.CLASS_NAMES = class_names\n",
    "CFG.NUM_CLASSES = num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc9f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data Augmentation\n",
    "# สร้าง Pipeline สำหรับ Training Set (มีการสุ่มปรับแต่งภาพ)\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(CFG.IMG_SIZE, CFG.IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# สร้าง Pipeline สำหรับ Validation/Test Set (ไม่มีการสุ่มปรับแต่ง)\n",
    "valid_transforms = A.Compose([\n",
    "    A.Resize(CFG.IMG_SIZE, CFG.IMG_SIZE),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce615a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Custom Dataset Class\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, data_path, class_names, transforms=None):\n",
    "        self.image_paths = glob.glob(os.path.join(data_path, '*/*.jpg')) + \\\n",
    "                           glob.glob(os.path.join(data_path, '*/*.JPG')) + \\\n",
    "                           glob.glob(os.path.join(data_path, '*/*.jpeg'))\n",
    "        \n",
    "        self.class_names = class_names\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        # สร้าง mapping จากชื่อคลาส (str) ไปเป็น label (int)\n",
    "        self.class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        # อ่านภาพด้วย OpenCV (อ่านเป็น BGR)\n",
    "        image = cv2.imread(image_path)\n",
    "        # แปลงเป็น RGB ซึ่งเป็น Format ที่โมเดลส่วนใหญ่ใช้\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # ดึงชื่อคลาสจาก path\n",
    "        class_name = os.path.basename(os.path.dirname(image_path))\n",
    "        label = self.class_to_idx[class_name]\n",
    "        \n",
    "        # ทำ Augmentation ถ้ามี\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bf291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Create Datasets and DataLoaders\n",
    "\n",
    "# สร้าง Dataset\n",
    "train_dataset = PlantDiseaseDataset(CFG.TRAIN_PATH, CFG.CLASS_NAMES, transforms=train_transforms)\n",
    "valid_dataset = PlantDiseaseDataset(CFG.VALID_PATH, CFG.CLASS_NAMES, transforms=valid_transforms)\n",
    "\n",
    "# สร้าง DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=CFG.NUM_WORKERS\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=CFG.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.NUM_WORKERS\n",
    ")\n",
    "\n",
    "print(f\"จำนวน Training batches: {len(train_loader)}\")\n",
    "print(f\"จำนวน Validation batches: {len(valid_loader)}\")\n",
    "\n",
    "# --- ตรวจสอบการทำงานของ DataLoader ---\n",
    "# ลองดึงข้อมูล 1 batch ออกมาดู\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Shape ของ image batch: {images.shape}\") # (Batch Size, Channels, Height, Width)\n",
    "print(f\"Shape ของ label batch: {labels.shape}\") # (Batch Size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create Model\n",
    "\n",
    "# โหลดโมเดล ConvNeXt-tiny ที่ pre-trained บน ImageNet\n",
    "# และแก้ไขจำนวนคลาสของชั้นสุดท้ายให้เท่ากับโจทย์ของเรา\n",
    "model = timm.create_model(\n",
    "    CFG.MODEL_NAME,\n",
    "    pretrained=True,\n",
    "    num_classes=CFG.NUM_CLASSES\n",
    ")\n",
    "\n",
    "# ย้ายโมเดลไปทำงานบน GPU (ถ้ามี)\n",
    "model.to(CFG.DEVICE)\n",
    "\n",
    "# แสดงจำนวนพารามิเตอร์ของโมเดล\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model: {CFG.MODEL_NAME}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e962e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Training and Validation Functions\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train() # ตั้งค่าโมเดลเป็น training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # ใช้ tqdm เพื่อแสดง progress bar\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        # ย้ายข้อมูลไปที่ GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad() # ล้างค่า gradient เก่า\n",
    "        loss.backward() # คำนวณ gradient\n",
    "        optimizer.step() # อัปเดตน้ำหนัก\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "def validate_one_epoch(model, dataloader, criterion, device):\n",
    "    model.eval() # ตั้งค่าโมเดลเป็น evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad(): # ไม่ต้องคำนวณ gradient ตอนวัดผล\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # หาคลาสที่โมเดลทำนาย\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            correct_predictions += torch.sum(preds == labels.data)\n",
    "            \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = correct_predictions.double() / len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_acc.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: The Main Training Loop\n",
    "\n",
    "# กำหนด Loss function และ Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.LEARNING_RATE)\n",
    "\n",
    "# ตัวแปรสำหรับเก็บผลลัพธ์ที่ดีที่สุด\n",
    "best_val_acc = 0.0\n",
    "best_model_path = f\"{CFG.MODEL_NAME}_best.pth\"\n",
    "\n",
    "# เริ่มการเทรน\n",
    "for epoch in range(CFG.EPOCHS):\n",
    "    print(f\"--- Epoch {epoch+1}/{CFG.EPOCHS} ---\")\n",
    "    \n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, CFG.DEVICE)\n",
    "    val_loss, val_acc = validate_one_epoch(model, valid_loader, criterion, CFG.DEVICE)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # บันทึกโมเดลที่ดีที่สุด\n",
    "    if val_acc > best_val_acc:\n",
    "        print(f\"Validation accuracy improved from {best_val_acc:.4f} to {val_acc:.4f}. Saving model...\")\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        \n",
    "print(\"Finished Training!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Best model saved to: {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b01147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Evaluation on the Validation Set\n",
    "\n",
    "# โหลดโมเดลที่ดีที่สุดกลับมา\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=CFG.DEVICE))\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(valid_loader, desc=\"Evaluating\"):\n",
    "        images = images.to(CFG.DEVICE)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "print(\"Evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Displaying Evaluation Results\n",
    "\n",
    "# แสดง Classification Report\n",
    "report = classification_report(all_labels, all_preds, target_names,CFG.CLASS_NAMES, zero_division=0)\n",
    "print(\"--- Classification Report ---\")\n",
    "print(report)\n",
    "\n",
    "# แสดง Confusion Matrix\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CFG.CLASS_NAMES)\n",
    "\n",
    "# ทำให้ figure ใหญ่ขึ้นและหมุน label เพื่อให้อ่านง่าย\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf382bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Inference Function\n",
    "\n",
    "def predict_one_image(image_path, model, transforms, class_names, device):\n",
    "    # อ่านและแปลงภาพ\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # ทำ pre-processing\n",
    "    transformed_image = transforms(image=image)['image']\n",
    "    \n",
    "    # เพิ่มมิติของ batch (1, C, H, W) และย้ายไป GPU\n",
    "    image_tensor = transformed_image.unsqueeze(0).to(device)\n",
    "    \n",
    "    # ทำนายผล\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        # แปลง output (logits) เป็นความน่าจะเป็น (probabilities)\n",
    "        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "        \n",
    "        # หาคลาสที่มีความน่าจะเป็นสูงสุด\n",
    "        confidence, pred_idx = torch.max(probabilities, 0)\n",
    "        \n",
    "    predicted_class = class_names[pred_idx.item()]\n",
    "    \n",
    "    return predicted_class, confidence.item()\n",
    "\n",
    "# --- ทดลองใช้งานฟังก์ชัน ---\n",
    "# สุ่มภาพจาก validation set มา 1 ภาพ\n",
    "sample_image_path = valid_dataset.image_paths[np.random.randint(len(valid_dataset))]\n",
    "\n",
    "# ทำนายผล\n",
    "predicted_class, confidence = predict_one_image(sample_image_path, model, valid_transforms, CFG.CLASS_NAMES, CFG.DEVICE)\n",
    "\n",
    "# แสดงผล\n",
    "img_display = cv2.imread(sample_image_path)\n",
    "img_display = cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_display)\n",
    "plt.title(f\"Predicted: {predicted_class}\\nConfidence: {confidence:.4f}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Setup for Submission\n",
    "\n",
    "# --- (สมมติฐาน) กำหนดให้โฟลเดอร์ valid คือโฟลเดอร์ test ของเรา ---\n",
    "CFG.TEST_PATH = CFG.VALID_PATH\n",
    "print(f\"Test data path is set to: {CFG.TEST_PATH}\")\n",
    "\n",
    "# ค้นหาไฟล์ภาพทั้งหมดในโฟลเดอร์ test\n",
    "test_image_paths = glob.glob(os.path.join(CFG.TEST_PATH, '*/*.*'))\n",
    "# ดึงมาเฉพาะชื่อไฟล์\n",
    "test_filenames = [os.path.basename(p) for p in test_image_paths]\n",
    "\n",
    "print(f\"พบรูปภาพสำหรับทดสอบทั้งหมด: {len(test_filenames)} รูป\")\n",
    "\n",
    "# --- สร้างไฟล์ sample_submission.csv จำลอง ---\n",
    "# เพื่อให้เห็นภาพว่า Format ที่ต้องการเป็นอย่างไร\n",
    "sample_df = pd.DataFrame({\n",
    "    'image': test_filenames[:5], # เอาแค่ 5 รูปแรกมาเป็นตัวอย่าง\n",
    "    'label': ['' for _ in range(5)] # คอลัมน์ label จะเว้นว่างไว้ให้เราเติม\n",
    "})\n",
    "print(\"\\nตัวอย่างรูปแบบของไฟล์ submission ที่ต้องการ:\")\n",
    "display(sample_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb142f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Create Test Dataset and DataLoader\n",
    "\n",
    "class PlantTestDataset(Dataset):\n",
    "    def __init__(self, data_path, transforms=None):\n",
    "        self.image_paths = glob.glob(os.path.join(data_path, '*/*.*'))\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        # ดึงชื่อไฟล์เพื่อใช้เป็น ID\n",
    "        image_id = os.path.basename(image_path)\n",
    "        \n",
    "        # อ่านและแปลงภาพ\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # ทำ Augmentation (ในที่นี้คือ valid_transforms)\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        return image, image_id\n",
    "\n",
    "\n",
    "# สร้าง Test Dataset และ DataLoader\n",
    "test_dataset = PlantTestDataset(CFG.TEST_PATH, transforms=valid_transforms)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CFG.BATCH_SIZE * 2, # ใช้ batch size ใหญ่ขึ้นได้ตอน inference เพราะไม่ต้องเก็บ gradient\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.NUM_WORKERS\n",
    ")\n",
    "\n",
    "print(f\"สร้าง Test Dataloader สำเร็จ มีทั้งหมด {len(test_loader)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d24e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Inference on Test Set\n",
    "\n",
    "# โหลดโมเดลที่ดีที่สุดกลับมา\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=CFG.DEVICE))\n",
    "model.eval() # *** สำคัญมาก: ตั้งค่าเป็น Evaluation Mode ***\n",
    "\n",
    "# List สำหรับเก็บผลลัพธ์\n",
    "results = []\n",
    "\n",
    "# ไม่ต้องคำนวณ gradient\n",
    "with torch.no_grad():\n",
    "    for images, image_ids in tqdm(test_loader, desc=\"Predicting on test data\"):\n",
    "        images = images.to(CFG.DEVICE)\n",
    "        \n",
    "        # ทำนายผล\n",
    "        outputs = model(images)\n",
    "        _, preds_indices = torch.max(outputs, 1)\n",
    "        \n",
    "        # แปลง index กลับเป็นชื่อคลาส\n",
    "        preds_labels = [CFG.CLASS_NAMES[i] for i in preds_indices.cpu().numpy()]\n",
    "        \n",
    "        # จับคู่ชื่อไฟล์กับคำทำนายแล้วเก็บใน list\n",
    "        for img_id, label in zip(image_ids, preds_labels):\n",
    "            results.append({'image': img_id, 'label': label})\n",
    "\n",
    "print(f\"\\nทำนายผลเสร็จสิ้น! มีผลลัพธ์ทั้งหมด {len(results)} รายการ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Create and Save Submission File\n",
    "\n",
    "# แปลง list ของผลลัพธ์เป็น DataFrame\n",
    "submission_df = pd.DataFrame(results)\n",
    "\n",
    "# บันทึกเป็นไฟล์ CSV\n",
    "# index=False คือการไม่เซฟคอลัมน์ index ของ DataFrame ลงในไฟล์ ซึ่งสำคัญมาก\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"สร้างไฟล์ submission.csv สำเร็จ!\")\n",
    "print(\"ตัวอย่าง 10 แถวแรกของไฟล์:\")\n",
    "display(submission_df.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
