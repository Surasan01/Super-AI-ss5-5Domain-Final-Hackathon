{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335bc4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Data Preparation\n",
    "\n",
    "# --- ติดตั้ง Libraries ---\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install opencv-python-headless pandas numpy matplotlib scikit-learn --quiet\n",
    "\n",
    "# --- Import Libraries ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- จำลองการสร้างข้อมูล (ในชีวิตจริง ส่วนนี้คือการเตรียมข้อมูลของคุณ) ---\n",
    "# สมมติว่าคุณมีโฟลเดอร์ 'license_plates' ที่เก็บภาพป้ายทะเบียน\n",
    "# และมีไฟล์ 'labels.csv' หน้าตาแบบนี้:\n",
    "#\n",
    "# filename,text\n",
    "# plate001.png,2กข 1234\n",
    "# plate002.png,1ขง 5678\n",
    "# plate003.png,กท 9999\n",
    "\n",
    "# สร้างโฟลเดอร์และไฟล์จำลอง\n",
    "if not os.path.exists('license_plates'):\n",
    "    os.makedirs('license_plates')\n",
    "\n",
    "# สร้าง DataFrame จำลอง\n",
    "mock_data = {\n",
    "    'filename': ['plate001.png', 'plate002.png', 'plate003.png', 'plate004.png'],\n",
    "    'text': ['2กข1234', '1ขง5678', 'กท9999', '9กอ777'] # เอาเว้นวรรคออกเพื่อความง่าย\n",
    "}\n",
    "df = pd.DataFrame(mock_data)\n",
    "\n",
    "# สร้างไฟล์ภาพเปล่าๆ จำลอง\n",
    "for fname in df['filename']:\n",
    "    cv2.imwrite(os.path.join('license_plates', fname), np.zeros((50, 200, 3), dtype=np.uint8))\n",
    "\n",
    "print(\"Data simulation complete.\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb89048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Character Mapping\n",
    "\n",
    "# --- กำหนดชุดตัวอักษรและตัวเลขทั้งหมดที่เป็นไปได้ ---\n",
    "CHARS = 'กขคงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรลวศษสหฬอฮ0123456789'\n",
    "# เพิ่ม CTC blank token ที่ index 0\n",
    "CTC_CHARS = '-' + CHARS\n",
    "\n",
    "# --- สร้าง Dictionary สำหรับแปลงตัวอักษรเป็นตัวเลข และ ngược lại ---\n",
    "char_to_int = {char: i for i, char in enumerate(CTC_CHARS)}\n",
    "int_to_char = {i: char for i, char in enumerate(CTC_CHARS)}\n",
    "\n",
    "NUM_CLASSES = len(CTC_CHARS)\n",
    "\n",
    "print(f\"Total characters: {len(CHARS)}\")\n",
    "print(f\"Total classes (including CTC blank): {NUM_CLASSES}\")\n",
    "print(\"Sample mapping:\", {k: char_to_int[k] for k in list(char_to_int)[:5]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd1763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Custom Dataset for OCR\n",
    "\n",
    "class OCRDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, char_to_int_map):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.char_to_int = char_to_int_map\n",
    "        # ปรับขนาดภาพและแปลงเป็น Tensor\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((64, 200)), # (Height, Width)\n",
    "            transforms.Grayscale(num_output_channels=1), # ใช้ภาพขาว-ดำ\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        text_label = row['text']\n",
    "        encoded_label = [self.char_to_int[char] for char in text_label]\n",
    "        \n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"label\": torch.tensor(encoded_label, dtype=torch.long),\n",
    "            \"label_length\": torch.tensor([len(text_label)], dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "# --- สร้าง DataLoader ---\n",
    "# CTC Loss ต้องการ Batch ที่ข้อมูลถูกเรียงต่อกัน เราจึงต้องสร้าง custom collate_fn\n",
    "def collate_fn(batch):\n",
    "    images = torch.stack([item['image'] for item in batch])\n",
    "    labels = [item['label'] for item in batch]\n",
    "    label_lengths = torch.stack([item['label_length'] for item in batch]).squeeze()\n",
    "\n",
    "    # Padding labels to the same length\n",
    "    labels_padded = nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return images, labels_padded, label_lengths\n",
    "\n",
    "\n",
    "# สร้าง Dataset\n",
    "full_dataset = OCRDataset(df, 'license_plates', char_to_int)\n",
    "# สร้าง DataLoader\n",
    "data_loader = DataLoader(\n",
    "    dataset=full_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# --- ตรวจสอบข้อมูลจาก DataLoader ---\n",
    "images, labels, label_lengths = next(iter(data_loader))\n",
    "print(\"Image batch shape:\", images.shape) # (Batch, Channels, Height, Width)\n",
    "print(\"Labels batch shape:\", labels.shape)\n",
    "print(\"Label lengths:\", label_lengths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f8fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: CRNN Model Architecture\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        \n",
    "        # --- CNN Feature Extractor ---\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2), # -> 32x100\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2), # -> 16x50\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)), # -> 8x50\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)), # -> 4x50\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512), nn.ReLU(True) # -> 4x50\n",
    "        )\n",
    "        \n",
    "        # --- Reshape for RNN ---\n",
    "        # หลัง CNN, shape จะเป็น (batch, 512, 4, 50)\n",
    "        # เราต้องแปลงเป็น (batch, 4*512, 50) -> (batch, 2048, 50)\n",
    "        # แล้วสลับมิติเป็น (seq_len, batch, input_size) สำหรับ RNN\n",
    "        # seq_len คือความกว้างของภาพ (50), input_size คือ 2048\n",
    "        \n",
    "        # --- RNN Sequence Predictor ---\n",
    "        self.rnn = nn.Sequential(\n",
    "            nn.LSTM(2048, 256, bidirectional=True),\n",
    "            nn.LSTM(512, 256, bidirectional=True)\n",
    "        )\n",
    "        \n",
    "        # --- Fully Connected Layer ---\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN part\n",
    "        x = self.cnn(x)\n",
    "        \n",
    "        # Reshape for RNN\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.view(b, c * h, w)\n",
    "        x = x.permute(2, 0, 1) # (Width, Batch, Channels*Height)\n",
    "        \n",
    "        # RNN part\n",
    "        x, _ = self.rnn(x)\n",
    "        \n",
    "        # FC part\n",
    "        x = self.fc(x) # Output shape: (seq_len, batch, num_classes)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# --- สร้างโมเดลและย้ายไป GPU ถ้ามี ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CRNN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "print(f\"Model created and moved to {DEVICE}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 (Updated): Training Loop with CTC Loss and Model Saving\n",
    "\n",
    "# --- กำหนด Loss และ Optimizer ---\n",
    "criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 50 \n",
    "MODEL_SAVE_PATH = \"crnn_tha_license_plate.pth\"\n",
    "\n",
    "model.train()\n",
    "import tqdm\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    # ใช้ tqdm เพื่อให้เห็น progress bar\n",
    "    for batch in tqdm(data_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        images = batch[\"image\"].to(DEVICE)\n",
    "        labels = batch[\"label\"]\n",
    "        label_lengths = batch[\"label_length\"]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        log_probs = nn.functional.log_softmax(outputs, dim=2)\n",
    "        \n",
    "        # Calculate loss\n",
    "        input_lengths = torch.full(size=(images.size(0),), fill_value=outputs.size(0), dtype=torch.long)\n",
    "        loss = criterion(log_probs, labels, input_lengths, label_lengths)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {epoch_loss/len(data_loader):.4f}\")\n",
    "\n",
    "# --- บันทึกโมเดลหลังจากการฝึกเสร็จสิ้น ---\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"\\nTraining finished. Model saved to {MODEL_SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Inference and Decoding\n",
    "\n",
    "def decode_prediction(preds, int_to_char_map):\n",
    "    preds = preds.permute(1, 0, 2) # (Batch, SeqLen, Classes)\n",
    "    preds = torch.argmax(preds, dim=2)\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    \n",
    "    decoded_texts = []\n",
    "    for pred in preds:\n",
    "        text = \"\"\n",
    "        for i in range(len(pred)):\n",
    "            # ลบตัวซ้ำและ blank\n",
    "            if pred[i] != 0 and (i == 0 or pred[i] != pred[i-1]):\n",
    "                text += int_to_char_map[pred[i]]\n",
    "        decoded_texts.append(text)\n",
    "    return decoded_texts\n",
    "\n",
    "\n",
    "# --- ทดลองทำนายผล ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # นำข้อมูลชุดแรกมาทดสอบ\n",
    "    images, labels, label_lengths = next(iter(data_loader))\n",
    "    images = images.to(DEVICE)\n",
    "    \n",
    "    # ทำนายผล\n",
    "    preds = model(images)\n",
    "    \n",
    "    # ถอดรหัส\n",
    "    predicted_texts = decode_prediction(preds, int_to_char)\n",
    "    \n",
    "    # ถอดรหัส Ground Truth เพื่อเปรียบเทียบ\n",
    "    true_texts = []\n",
    "    for label in labels:\n",
    "        true_texts.append(\"\".join([int_to_char[i] for i in label if i != 0]))\n",
    "        \n",
    "    # แสดงผล\n",
    "    for i in range(len(images)):\n",
    "        plt.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
    "        plt.title(f\"True: {true_texts[i]}\\nPred: {predicted_texts[i]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfde74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Inference on Test Set and Submission File Generation\n",
    "\n",
    "# --- 1. จำลอง Test Set ---\n",
    "# ในชีวิตจริง คุณจะมีโฟลเดอร์ test อยู่แล้ว\n",
    "TEST_IMG_DIR = 'test_plates'\n",
    "if not os.path.exists(TEST_IMG_DIR):\n",
    "    os.makedirs(TEST_IMG_DIR)\n",
    "\n",
    "# สร้าง DataFrame สำหรับ test set\n",
    "mock_test_data = {'filename': ['test001.png', 'test002.png']}\n",
    "test_df = pd.DataFrame(mock_test_data)\n",
    "\n",
    "# สร้างไฟล์ภาพเปล่าๆ จำลอง\n",
    "for fname in test_df['filename']:\n",
    "    cv2.imwrite(os.path.join(TEST_IMG_DIR, fname), np.zeros((50, 200, 3), dtype=np.uint8))\n",
    "\n",
    "print(f\"Test set simulated with {len(test_df)} images.\")\n",
    "\n",
    "\n",
    "# --- 2. สร้าง Dataset และ DataLoader สำหรับ Test ---\n",
    "class TestOCRDataset(Dataset):\n",
    "    def __init__(self, df, img_dir):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((64, 200)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        filename = row['filename']\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = self.transform(image)\n",
    "        return image, filename\n",
    "\n",
    "test_dataset = TestOCRDataset(test_df, TEST_IMG_DIR)\n",
    "# สำหรับ Test, batch_size อาจจะใหญ่ขึ้นได้ และไม่ต้องมี collate_fn ที่ซับซ้อน\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "\n",
    "# --- 3. โหลดโมเดลและทำนายผล ---\n",
    "# สร้าง instance ของโมเดลและโหลด state ที่บันทึกไว้\n",
    "inference_model = CRNN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "inference_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "inference_model.eval() # ตั้งเป็น evaluation mode\n",
    "\n",
    "# ฟังก์ชันถอดรหัสจากขั้นตอนที่ 6\n",
    "def decode_prediction(preds, int_to_char_map):\n",
    "    preds = preds.permute(1, 0, 2)\n",
    "    preds = torch.argmax(preds, dim=2)\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    \n",
    "    decoded_texts = []\n",
    "    for pred in preds:\n",
    "        text = \"\"\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i] != 0 and (i == 0 or pred[i] != pred[i-1]):\n",
    "                text += int_to_char_map[pred[i]]\n",
    "        decoded_texts.append(text)\n",
    "    return decoded_texts\n",
    "\n",
    "# เก็บผลลัพธ์\n",
    "all_filenames = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, filenames in tqdm(test_loader, desc=\"Generating Predictions\"):\n",
    "        images = images.to(DEVICE)\n",
    "        \n",
    "        # ทำนายผล\n",
    "        preds = inference_model(images)\n",
    "        \n",
    "        # ถอดรหัส\n",
    "        predicted_texts = decode_prediction(preds, int_to_char)\n",
    "        \n",
    "        all_filenames.extend(filenames)\n",
    "        all_predictions.extend(predicted_texts)\n",
    "\n",
    "\n",
    "# --- 4. สร้างไฟล์ Submission ---\n",
    "submission_df = pd.DataFrame({\n",
    "    'filename': all_filenames,\n",
    "    'predicted_text': all_predictions\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nsubmission.csv created successfully!\")\n",
    "display(submission_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
