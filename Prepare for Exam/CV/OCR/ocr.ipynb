{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571df5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Environment Installation\n",
    "!pip install opendatasets torch torchvision pandas matplotlib scikit-learn --quiet\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"Setup Complete. Libraries are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e55fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Acquisition & Preparation\n",
    "import opendatasets as od\n",
    "\n",
    "# ดาวน์โหลดข้อมูล CAPTCHA\n",
    "dataset_url = 'https://www.kaggle.com/datasets/fournierp/captcha-version-2-images'\n",
    "od.download(dataset_url)\n",
    "\n",
    "DATA_DIR = './captcha-version-2-images/samples/'\n",
    "\n",
    "# สร้าง DataFrame จากชื่อไฟล์\n",
    "image_files = glob.glob(os.path.join(DATA_DIR, '*.png'))\n",
    "labels = [os.path.splitext(os.path.basename(f))[0] for f in image_files]\n",
    "\n",
    "df = pd.DataFrame({'image_path': image_files, 'label': labels})\n",
    "\n",
    "print(f\"Found {len(df)} images.\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe569388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Parameters & Character Encoding\n",
    "\n",
    "# --- Parameters ---\n",
    "IMG_HEIGHT = 50\n",
    "IMG_WIDTH = 200\n",
    "MAX_LENGTH = 5 # ความยาวสูงสุดของข้อความใน CAPTCHA\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20 # โจทย์จริงอาจต้องใช้มากกว่านี้\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Character Encoding ---\n",
    "# หาชุดตัวอักษรทั้งหมดที่มีในข้อมูล\n",
    "all_chars = sorted(list(set(\"\".join(df['label']))))\n",
    "# เพิ่ม 'blank' token สำหรับ CTC Loss\n",
    "# token นี้จะอยู่ที่ index 0\n",
    "char_to_int = {char: i + 1 for i, char in enumerate(all_chars)}\n",
    "char_to_int['-'] = 0 # CTC blank token\n",
    "int_to_char = {i: char for char, i in char_to_int.items()}\n",
    "\n",
    "NUM_CLASSES = len(int_to_char)\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Number of classes (including blank token): {NUM_CLASSES}\")\n",
    "print(\"Character set:\", \"\".join(all_chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9ac2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Custom PyTorch Dataset for OCR\n",
    "\n",
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, df, char_map, max_length):\n",
    "        self.df = df\n",
    "        self.char_map = char_map\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = row['image_path']\n",
    "        label = row['label']\n",
    "\n",
    "        # --- Image Processing ---\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        image = image / 255.0  # Normalize to [0, 1]\n",
    "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0) # (1, H, W)\n",
    "\n",
    "        # --- Label Encoding ---\n",
    "        encoded_label = [self.char_map[char] for char in label]\n",
    "        label_tensor = torch.tensor(encoded_label, dtype=torch.long)\n",
    "        label_length = torch.tensor(len(label), dtype=torch.long)\n",
    "        \n",
    "        return image, label_tensor, label_length\n",
    "\n",
    "# แบ่งข้อมูล\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# สร้าง Datasets\n",
    "train_dataset = CaptchaDataset(train_df, char_to_int, MAX_LENGTH)\n",
    "val_dataset = CaptchaDataset(val_df, char_to_int, MAX_LENGTH)\n",
    "\n",
    "print(\"Datasets created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d9aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: The CRNN Model Architecture\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CRNN, self).__init__()\n",
    "        \n",
    "        # --- Part 1: Convolutional Layers (CNN) ---\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)), # (H, W) -> (6, 50) -> (3, 50)\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # --- Part 2: Recurrent Layers (RNN) ---\n",
    "        # ต้องคำนวณขนาด Feature ที่ออกจาก CNN ก่อน\n",
    "        # (Batch, C, H, W) -> (Batch, 512, 1, 50)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=512, # ขนาด feature จาก CNN\n",
    "            hidden_size=256,\n",
    "            num_layers=2,\n",
    "            bidirectional=True, # ใช้ LSTM ทั้งไปข้างหน้าและย้อนกลับ\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # --- Part 3: Classifier ---\n",
    "        self.classifier = nn.Linear(\n",
    "            in_features=512, # 256 (hidden) * 2 (bidirectional)\n",
    "            out_features=num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through CNN\n",
    "        features = self.cnn(x) # -> (B, C, H, W) e.g., (B, 512, 1, 50)\n",
    "        \n",
    "        # Reshape for RNN\n",
    "        features = features.squeeze(2) # -> (B, C, W) e.g., (B, 512, 50)\n",
    "        features = features.permute(0, 2, 1) # -> (B, W, C) e.g., (B, 50, 512)\n",
    "        \n",
    "        # Pass through RNN\n",
    "        rnn_output, _ = self.rnn(features) # -> (B, SeqLen, Features) e.g., (B, 50, 512)\n",
    "        \n",
    "        # Pass through Classifier\n",
    "        output = self.classifier(rnn_output) # -> (B, SeqLen, NumClasses) e.g., (B, 50, 20)\n",
    "        \n",
    "        # Reshape for CTC Loss\n",
    "        output = output.permute(1, 0, 2) # -> (SeqLen, B, NumClasses) REQUIRED BY CTC\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Collate Function, DataLoaders, and Initialization\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels, label_lengths = zip(*batch)\n",
    "    images = torch.stack(images, 0)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=0)\n",
    "    label_lengths = torch.stack(label_lengths, 0)\n",
    "    return images, labels, label_lengths\n",
    "\n",
    "# สร้าง DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# --- Initialization ---\n",
    "model = CRNN(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "loss_fn = nn.CTCLoss(blank=0, zero_infinity=True) # blank=0 คือ index ของ blank token\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(\"Model, Loss, and Optimizer are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1726bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: CTC Decode Function\n",
    "\n",
    "def ctc_decode(preds, int_to_char_map):\n",
    "    # preds shape: (SeqLen, Batch, NumClasses)\n",
    "    preds = preds.permute(1, 0, 2) # -> (Batch, SeqLen, NumClasses)\n",
    "    pred_indices = torch.argmax(preds, dim=2) # -> (Batch, SeqLen)\n",
    "    \n",
    "    decoded_texts = []\n",
    "    for indices in pred_indices:\n",
    "        text = []\n",
    "        last_char_idx = -1\n",
    "        for idx in indices:\n",
    "            # ไม่เอาตัวซ้ำและ blank token\n",
    "            if idx.item() != last_char_idx and idx.item() != 0:\n",
    "                text.append(int_to_char_map[idx.item()])\n",
    "            last_char_idx = idx.item()\n",
    "        decoded_texts.append(\"\".join(text))\n",
    "        \n",
    "    return decoded_texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: The Training Loop\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{EPOCHS} ---\")\n",
    "    \n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels, label_lengths in tqdm(train_loader, desc=\"Training\"):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        preds = model(images) # -> (SeqLen, Batch, NumClasses)\n",
    "        \n",
    "        # Prepare for CTC Loss\n",
    "        pred_lengths = torch.full(\n",
    "            size=(preds.size(1),), \n",
    "            fill_value=preds.size(0), \n",
    "            dtype=torch.long\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        loss = loss_fn(preds.log_softmax(2), labels, pred_lengths, label_lengths)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels, label_lengths in tqdm(val_loader, desc=\"Validating\"):\n",
    "            images = images.to(DEVICE)\n",
    "            preds = model(images)\n",
    "            \n",
    "            # Decode predictions and ground truth\n",
    "            decoded_preds = ctc_decode(preds, int_to_char)\n",
    "            \n",
    "            # ต้องถอดรหัส label กลับไปเป็น text เพื่อเทียบกัน\n",
    "            # เพราะ CTC Loss ไม่ได้คำนวณ accuracy ตรงๆ\n",
    "            true_labels = []\n",
    "            for l in labels:\n",
    "                true_labels.append(\"\".join([int_to_char[i.item()] for i in l if i != 0]))\n",
    "            \n",
    "            for pred, true in zip(decoded_preds, true_labels):\n",
    "                if pred == true:\n",
    "                    val_correct += 1\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    val_acc = val_correct / len(val_dataset)\n",
    "    \n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "print(\"\\nFinished Training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f260519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Visualize Predictions & Generate Submission\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# แสดงผล 5 ภาพตัวอย่าง\n",
    "for i in range(5):\n",
    "    # สุ่มภาพจาก validation set\n",
    "    idx = np.random.randint(len(val_dataset))\n",
    "    image, label_tensor, _ = val_dataset[idx]\n",
    "    true_label = \"\".join([int_to_char[i.item()] for i in label_tensor])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(image.unsqueeze(0).to(DEVICE))\n",
    "        decoded_pred = ctc_decode(pred, int_to_char)[0]\n",
    "\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.imshow(image.squeeze().cpu(), cmap='gray')\n",
    "    plt.title(f\"True: {true_label} | Pred: {decoded_pred}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# --- สร้างไฟล์ Submission (จำลองโดยใช้ valal_df) ---\n",
    "submission_df = val_df.copy()\n",
    "all_preds = []\n",
    "test_loader_sub = DataLoader(val_dataset, batchize=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _, _ in tqdm(test_loader_sub, desc=\"Generating Submission\"):\n",
    "        images = images.to(DEVICE)\n",
    "        preds = model(images)\n",
    "        decoded_preds = ctc_decode(preds, int_to_char)\n",
    "        all_preds.extend(decoded_preds)\n",
    "\n",
    "submission_df['predicted_label'] = all_preds\n",
    "submission_df = submission_df[['image_path', 'label', 'predicted_label']]\n",
    "submission_df['image_path'] = submission_df['image_path'].apply(os.path.basename)\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"\\nsubmission.csv created successfully!\")\n",
    "display(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f51bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff6ed08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
